---
always_allow_html: yes
output:
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
  html_vignette:
    toc: yes
    toc_depth: 3
    vignette: >
      %\VignetteIndexEntry{latestChanges}
      %\VignetteEngine{knitr::rmarkdown}
      %\VignetteEncoding{UTF-8}
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Subject ID conversion
As of TreatmentPatterns `2.7.0` TreatmentPatterns will assign it's own pseudo subject ID's. This is due to subject ID's in the database may be 64 bit integers, or may contain letters. This can lead to strange edge cases where ID's get rounded, and results of different individuals will be grouped together.

The real ID's that exist in the database will be stored as a `character(1)` in the `cohortTable` table, in the patient level result object from `computePathways()`

In the following snipit of code we will show how to relate the internal ID's to the ID's existing in the database:
```{r}
library(TreatmentPatterns)
library(CDMConnector)
library(dplyr)

con <- DBI::dbConnect(duckdb::duckdb(), dbdir = eunomia_dir())
cdm <- cdmFromCon(con, cdmSchema = "main", writeSchema = "main")
cohortSet <- readCohortSet(
 path = system.file(package = "TreatmentPatterns", "exampleCohorts")
)

cdm <- generateCohortSet(
 cdm = cdm,
 cohortSet = cohortSet,
 name = "cohort_table"
)

# convert subject_id to subject_id + 1e16 as 64 bit integer
cdm$cohort_table <- cdm$cohort_table %>%
  mutate(subject_id = bit64::as.integer64(.data$subject_id + 1e16)) %>%
  compute()

cdm$person <- cdm$person %>%
  mutate(person_id = bit64::as.integer64(.data$person_id + 1e16)) %>%
  compute()

cohorts <- cohortSet %>%
 # Remove 'cohort' and 'json' columns
 select(-"cohort", -"json") %>%
 mutate(type = c("event", "event", "event", "event", "exit", "event", "event", "target")) %>%
 rename(
   cohortId = "cohort_definition_id",
   cohortName = "cohort_name",
 ) %>%
 select("cohortId", "cohortName", "type")

outputEnv <- computePathways(
 cohorts = cohorts,
 cohortTableName = "cohort_table",
 cdm = cdm
)

outputEnv$treatmentHistory %>%
  inner_join(outputEnv$cohortTable, join_by(personId == personId)) %>%
  select("personId", "subject_id_origin") %>%
  head()

Andromeda::close(outputEnv)
DBI::dbDisconnect(con, shutdown = TRUE)
```

## `periodPriorToIndex` to `indexDateOffset`
The `periodPriorToIndex` parameter has been renamed to `indexDateOffset`. It was already possible to use the parameter as an offset, with negative numbers. But this change solidifies this use-case.

Note that the logic is not inversed. If you want to look back for 30 days prior to the index date previously you would set `periodPriorToIndex = 30` which now equals `indexDateOffset = -30`.

```{r}
library(TreatmentPatterns)
library(CDMConnector)
library(dplyr)

con <- DBI::dbConnect(duckdb::duckdb(), dbdir = eunomia_dir())
cdm <- cdmFromCon(con, cdmSchema = "main", writeSchema = "main")
cohortSet <- readCohortSet(
 path = system.file(package = "TreatmentPatterns", "exampleCohorts")
)

cdm <- generateCohortSet(
 cdm = cdm,
 cohortSet = cohortSet,
 name = "cohort_table"
)

# convert subject_id to subject_id + 1e16 as 64 bit integer
cdm$cohort_table <- cdm$cohort_table %>%
  mutate(subject_id = bit64::as.integer64(.data$subject_id + 1e16)) %>%
  compute()

cdm$person <- cdm$person %>%
  mutate(person_id = bit64::as.integer64(.data$person_id + 1e16)) %>%
  compute()

cohorts <- cohortSet %>%
 # Remove 'cohort' and 'json' columns
 select(-"cohort", -"json") %>%
 mutate(type = c("event", "event", "event", "event", "exit", "event", "event", "target")) %>%
 rename(
   cohortId = "cohort_definition_id",
   cohortName = "cohort_name",
 ) %>%
 select("cohortId", "cohortName", "type")

outputEnv <- computePathways(
 cohorts = cohorts,
 cohortTableName = "cohort_table",
 cdm = cdm,
 # Look back (index date - 30 days)
 indexDateOffset = -30
)

outputEnv <- computePathways(
 cohorts = cohorts,
 cohortTableName = "cohort_table",
 cdm = cdm,
 # Look ahead (index date + 30 days)
 indexDateOffset = 30
)
```

## Empty data
In previous versions TreatmentPatterns, TreatmentPatterns would throw an ambiguous error from `dplyr` if the `target` was empty, wasn't assigned or other related issues.

Now TreatmentPatterns throws more informative errors and warnings when something like this is detected.
```{r error=TRUE}
library(TreatmentPatterns)
library(CDMConnector)
library(dplyr)

con <- DBI::dbConnect(duckdb::duckdb(), dbdir = eunomia_dir())
cdm <- cdmFromCon(con, cdmSchema = "main", writeSchema = "main")
cohortSet <- readCohortSet(
  path = system.file(package = "TreatmentPatterns", "exampleCohorts")
)

cdm <- generateCohortSet(
  cdm = cdm,
  cohortSet = cohortSet,
  name = "cohort_table"
)

# convert subject_id to subject_id + 1e16 as 64 bit integer
cdm$cohort_table <- cdm$cohort_table %>%
  mutate(subject_id = bit64::as.integer64(.data$subject_id + 1e16)) %>%
  compute()

cdm$person <- cdm$person %>%
  mutate(person_id = bit64::as.integer64(.data$person_id + 1e16)) %>%
  compute()

cohorts <- cohortSet %>%
 # Remove 'cohort' and 'json' columns
 select(-"cohort", -"json") %>%
 mutate(type = c("event", "event", "event", "event", "exit", "event", "event", "target")) %>%
 rename(
   cohortId = "cohort_definition_id",
   cohortName = "cohort_name",
 ) %>%
 select("cohortId", "cohortName", "type")

outputEnv <- computePathways(
  cohorts = cohorts,
  cohortTableName = "cohort_table",
  cdm = cdm,
  # Set minEraDuration, minPostCombinationWindow, and combinationWindow to
  # unreasonably large values, so no record qualifies.
  minEraDuration = 9999999,
  minPostCombinationDuration = 9999999,
  combinationWindow = 9999999
)

cohorts <- cohortSet %>%
 # Remove 'cohort' and 'json' columns
 select(-"cohort", -"json") %>%
  # Only set "event" types
 mutate(type = c("event", "event", "event", "event", "event", "event", "event", "event")) %>%
 rename(
   cohortId = "cohort_definition_id",
   cohortName = "cohort_name",
 ) %>%
 select("cohortId", "cohortName", "type")

outputEnv <- computePathways(
  cohorts = cohorts,
  cohortTableName = "cohort_table",
  cdm = cdm
)
```

## `summaryStatsTherapyDuration.csv` to `summaryEventDuration.csv`
The `summaryStatsTherapyDuration.csv` has been renamed to `summaryEventDuration.csv`. The file now fully focuses on the duration of events, across different levels in the pathways, and overall.
```{r}
library(TreatmentPatterns)
library(CDMConnector)
library(dplyr)

con <- DBI::dbConnect(duckdb::duckdb(), dbdir = eunomia_dir())
cdm <- cdmFromCon(con, cdmSchema = "main", writeSchema = "main")
cohortSet <- readCohortSet(
 path = system.file(package = "TreatmentPatterns", "exampleCohorts")
)

cdm <- generateCohortSet(
 cdm = cdm,
 cohortSet = cohortSet,
 name = "cohort_table"
)

# convert subject_id to subject_id + 1e16 as 64 bit integer
cdm$cohort_table <- cdm$cohort_table %>%
  mutate(subject_id = bit64::as.integer64(.data$subject_id + 1e16)) %>%
  compute()

cdm$person <- cdm$person %>%
  mutate(person_id = bit64::as.integer64(.data$person_id + 1e16)) %>%
  compute()

cohorts <- cohortSet %>%
 # Remove 'cohort' and 'json' columns
 select(-"cohort", -"json") %>%
 mutate(type = c("event", "event", "event", "event", "exit", "event", "event", "target")) %>%
 rename(
   cohortId = "cohort_definition_id",
   cohortName = "cohort_name",
 ) %>%
 select("cohortId", "cohortName", "type")

outputEnv <- computePathways(
 cohorts = cohorts,
 cohortTableName = "cohort_table",
 cdm = cdm
)

tempDir <- file.path(tempdir(), "tp")
export(outputEnv, outputPath = tempDir)

eventDuration <- read.csv(file.path(tempDir, "summaryEventDuration.csv"))

head(eventDuration)
```



## Event duration with `plotEventDuration()`
The Sunburst plot and Sankey diagram are limited in that they do not show anything about duration of events. The `plotEventDuration()` function is an attempt to also provide something meaningful about the duration of events:
```{r}
plotEventDuration(
  eventDurations = eventDuration,
  minCellCount = 5,
  treatmentGroups = "both",
  eventLines = NULL,
  includeOverall = TRUE
)

plotEventDuration(
  eventDurations = eventDuration,
  minCellCount = 5,
  treatmentGroups = "both",
  eventLines = NULL,
  includeOverall = FALSE
)

plotEventDuration(
  eventDurations = eventDuration,
  minCellCount = 5,
  treatmentGroups = "both",
  eventLines = c(2),
  includeOverall = TRUE
)

plotEventDuration(
  eventDurations = eventDuration,
  minCellCount = 5,
  treatmentGroups = "individual",
  eventLines = NULL,
  includeOverall = TRUE
)

plotEventDuration(
  eventDurations = eventDuration,
  minCellCount = 5,
  treatmentGroups = "group",
  eventLines = NULL,
  includeOverall = TRUE
)
```

## Attrition
Status messages have been updated when running `computePathways()`. All messages are now also recorded in an attrition table. Which keeps track of the number of records and subjects left in the analysis.
```{r}
library(TreatmentPatterns)
library(CDMConnector)
library(dplyr)

con <- DBI::dbConnect(duckdb::duckdb(), dbdir = eunomia_dir())
cdm <- cdmFromCon(con, cdmSchema = "main", writeSchema = "main")
cohortSet <- readCohortSet(
 path = system.file(package = "TreatmentPatterns", "exampleCohorts")
)

cdm <- generateCohortSet(
 cdm = cdm,
 cohortSet = cohortSet,
 name = "cohort_table"
)

# convert subject_id to subject_id + 1e16 as 64 bit integer
cdm$cohort_table <- cdm$cohort_table %>%
  mutate(subject_id = bit64::as.integer64(.data$subject_id + 1e16)) %>%
  compute()

cdm$person <- cdm$person %>%
  mutate(person_id = bit64::as.integer64(.data$person_id + 1e16)) %>%
  compute()

cohorts <- cohortSet %>%
 # Remove 'cohort' and 'json' columns
 select(-"cohort", -"json") %>%
 mutate(type = c("event", "event", "event", "event", "exit", "event", "event", "target")) %>%
 rename(
   cohortId = "cohort_definition_id",
   cohortName = "cohort_name",
 ) %>%
 select("cohortId", "cohortName", "type")

outputEnv <- computePathways(
 cohorts = cohorts,
 cohortTableName = "cohort_table",
 cdm = cdm
)

tempDir <- file.path(tempdir(), "tp")
export(outputEnv, outputPath = tempDir)

attrition <- read.csv(file.path(tempDir, "attrition.csv"))

attrition
```
The attrition table has the following columns:
  - number_records: Number of records left in the analysis, at any given stage.
  - number_subjects: Number of subjects in the analysis, at any given stage.
  - reason_id: Identification field per stage of the analysis.
  - reason: Description of why records were removed.
  - time: Time stamp as in number of seconds since 1970-01-01 (time since epoch).
